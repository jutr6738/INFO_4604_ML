{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55c8a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification\n",
    "\n",
    "#Classification is a very important area of supervised machine learning. \n",
    "#A large number of important machine learning problems fall within this area. \n",
    "#There are many classification methods, and logistic regression is one of them.\n",
    "\n",
    "#Other classification algorithms include:\n",
    "\n",
    "k-Nearest Neighbors\n",
    "Naive Bayes classifiers\n",
    "Support Vector Machines\n",
    "Decision Trees\n",
    "Random Forests\n",
    "Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdacac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff62ade1",
   "metadata": {},
   "source": [
    "# Example 1: Simple Logistic Regression with Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c2e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic Regression in Python With scikit-learn: Example 1\n",
    "\n",
    "#Our first example is related to a single-variate binary classification problem. \n",
    "#This is the most straightforward kind of classification problem. \n",
    "#There are several general steps you‚Äôll take when you‚Äôre preparing your classification models:\n",
    "\n",
    "#Step 1: Import packages, functions, and classes\n",
    "\n",
    "#Step 2: Get data to work with and, if appropriate, transform it\n",
    "\n",
    "#Step 3: Create a classification model and train (or fit) it with your existing data\n",
    "\n",
    "#Step 4: Evaluate your model to see if its performance is satisfactory\n",
    "\n",
    "#A sufficiently good model that you define can be used to make further predictions related to new, unseen data. \n",
    "#The above procedure is the same for classification and regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908a2fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Import Packages, Functions, and Classes\n",
    "\n",
    "#First, you have to import Matplotlib for visualization and NumPy for array operations. \n",
    "#You‚Äôll also need LogisticRegression, classification_report(), and confusion_matrix() from scikit-learn:\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9819e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbe5cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Get Data\n",
    "#In practice, you‚Äôll usually have some data to work with. \n",
    "#For the purpose of this example, let‚Äôs just create arrays for the input (ùë•) and output (ùë¶) values:\n",
    "\n",
    "x = np.arange(10).reshape(-1, 1)\n",
    "y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5007d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The input and output should be NumPy arrays (instances of the class numpy.ndarray) or similar objects. \n",
    "#numpy.arange() creates an array of consecutive, equally-spaced values within a given range. \n",
    "#For more information on this function, check the official documentation or NumPy arange(): How to Use np.arange().\n",
    "\n",
    "#The array x is required to be two-dimensional. \n",
    "#It should have one column for each input, and the number of rows should be equal to the number of observations. \n",
    "#To make x two-dimensional, you apply .reshape() with the arguments -1 to get as many rows as needed and 1 to get one column. \n",
    "#For more information on .reshape(), you can check out the official documentation. Here‚Äôs how x and y look now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5604980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09397224",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ca4626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that x has two dimensions:\n",
    "\n",
    "#One column for a single input\n",
    "#Ten rows, each corresponding to one observation\n",
    "#y is one-dimensional with ten items. Again, each item corresponds to one observation. \n",
    "#It contains only zeros and ones since this is a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36990426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8640e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 - 1: Create a classification model and train (or fit) it with your existing data\n",
    "\n",
    "#Once you have the input and output prepared, you can create and define your classification model. \n",
    "#You‚Äôre going to represent it with an instance of the class LogisticRegression:\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26499f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098d12ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d3ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The above statement creates an instance of LogisticRegression and binds its references to the variable model. \n",
    "#LogisticRegression has several optional parameters that define the behavior of the model and approach:\n",
    "\n",
    "#penalty is a string ('l2' by default) that decides whether there is regularization and which approach to use. Other options are 'l1', 'elasticnet', and 'none'.\n",
    "\n",
    "#dual is a Boolean (False by default) that decides whether to use primal (when False) or dual formulation (when True).\n",
    "\n",
    "#tol is a floating-point number (0.0001 by default) that defines the tolerance for stopping the procedure.\n",
    "\n",
    "#C is a positive floating-point number (1.0 by default) that defines the relative strength of regularization. Smaller values indicate stronger regularization.\n",
    "\n",
    "#fit_intercept is a Boolean (True by default) that decides whether to calculate the intercept ùëè‚ÇÄ (when True) or consider it equal to zero (when False).\n",
    "\n",
    "#intercept_scaling is a floating-point number (1.0 by default) that defines the scaling of the intercept ùëè‚ÇÄ.\n",
    "\n",
    "#class_weight is a dictionary, 'balanced', or None (default) that defines the weights related to each class. When None, all classes have the weight one.\n",
    "\n",
    "#random_state is an integer, an instance of numpy.RandomState, or None (default) that defines what pseudo-random number generator to use.\n",
    "\n",
    "#solver is a string ('liblinear' by default) that decides what solver to use for fitting the model. Other options are 'newton-cg', 'lbfgs', 'sag', and 'saga'.\n",
    "\n",
    "#max_iter is an integer (100 by default) that defines the maximum number of iterations by the solver during model fitting.\n",
    "\n",
    "#multi_class is a string ('ovr' by default) that decides the approach to use for handling multiple classes. Other options are 'multinomial' and 'auto'.\n",
    "\n",
    "#verbose is a non-negative integer (0 by default) that defines the verbosity for the 'liblinear' and 'lbfgs' solvers.\n",
    "\n",
    "#warm_start is a Boolean (False by default) that decides whether to reuse the previously obtained solution.\n",
    "\n",
    "#n_jobs is an integer or None (default) that defines the number of parallel processes to use. None usually means to use one core, while -1 means to use all available cores.\n",
    "\n",
    "#l1_ratio is either a floating-point number between zero and one or None (default). It defines the relative importance of the L1 part in the elastic-net regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a99fb2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5819f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You should carefully match the solver and regularization method for several reasons:\n",
    "\n",
    "#'liblinear' solver doesn‚Äôt work without regularization.\n",
    "#'newton-cg', 'sag', 'saga', and 'lbfgs' don‚Äôt support L1 regularization.\n",
    "#'saga' is the only solver that supports elastic-net regularization.\n",
    "#Once the model is created, you need to fit (or train) it. \n",
    "\n",
    "#Model fitting is the process of determining the coefficients ùëè‚ÇÄ, ùëè‚ÇÅ, ‚Ä¶, ùëè·µ£ that correspond to the best value of the cost function. \n",
    "#You fit the model with .fit():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee46cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 - 2: Create a classification model and train (or fit) it with your existing data\n",
    "\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249ed374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.fit() takes x, y, and possibly observation-related weights. Then it fits the model and returns the model instance itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88292925",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69b20ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the obtained string representation of the fitted model.\n",
    "\n",
    "#You can use the fact that .fit() returns the model instance and chain the last two statements. \n",
    "#They are equivalent to the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ec56ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=0).fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f3075b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c477561",
   "metadata": {},
   "outputs": [],
   "source": [
    "#At this point, you have the classification model defined.\n",
    "\n",
    "#You can quickly get the attributes of your model. \n",
    "#For example, the attribute .classes_ represents the array of distinct values that y takes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9142e1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87983b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the example of binary classification, and y can be 0 or 1, as indicated above.\n",
    "\n",
    "#You can also get the value of the slope ùëè‚ÇÅ and the intercept ùëè‚ÇÄ of the linear function ùëì like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c18a554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can also get the value of the intercept ùëè‚ÇÄ of the linear function ùëì like so:\n",
    "\n",
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1545f106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac27e4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can also get the value of the slope ùëè‚ÇÅ the linear function ùëì like so:\n",
    "\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c00c041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As you can see, ùëè‚ÇÄ is given inside a one-dimensional array, while ùëè‚ÇÅ is inside a two-dimensional array. \n",
    "#You use the attributes .intercept_ and .coef_ to get these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d90ddb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef29c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Evaluate the Model\n",
    "#Once a model is defined, you can check its performance with .predict_proba(), \n",
    "#which returns the matrix of probabilities that the predicted output is equal to zero or one:\n",
    "\n",
    "\n",
    "model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ac3d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the matrix above, each row corresponds to a single observation. \n",
    "#The first column is the probability of the predicted output being zero, that is 1 - ùëù(ùë•). \n",
    "#The second column is the probability that the output is one, or ùëù(ùë•)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f29253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55be3186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4-1: Obtain actual predictions\n",
    "#You can get the actual predictions, based on the probability matrix and the values of ùëù(ùë•), with .predict():\n",
    "\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f3a103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae99339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4-2\n",
    "\n",
    "#.score() takes the input and output as arguments and returns \n",
    "#the ratio of the number of correct predictions to the number of observations\n",
    "\n",
    "model.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33629642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b10676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can get more information on the accuracy of the model with a confusion matrix. \n",
    "#In the case of binary classification, the confusion matrix shows the numbers of the following:\n",
    "\n",
    "#True negatives in the upper-left position\n",
    "#False negatives in the lower-left position\n",
    "#False positives in the upper-right position\n",
    "#True positives in the lower-right position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8075cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ecf6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4-3\n",
    "\n",
    "#To create the confusion matrix, you can use confusion_matrix() \n",
    "#and provide the actual and predicted outputs as the arguments:\n",
    "\n",
    "confusion_matrix(y, model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0553a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afdb498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The obtained matrix shows the following:\n",
    "\n",
    "#Three true negative predictions: The first three observations are zeros predicted correctly.\n",
    "#No false negative predictions: These are the ones wrongly predicted as zeros.\n",
    "#One false positive prediction: The fourth observation is a zero that was wrongly predicted as one.\n",
    "#Six true positive predictions: The last six observations are ones predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5579d768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4277219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4-4\n",
    "#It‚Äôs often useful to visualize the confusion matrix. \n",
    "#You can do that with .imshow() from Matplotlib, which accepts the confusion matrix as the argument:\n",
    "\n",
    "cm = confusion_matrix(y, model.predict(x))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3699b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d65408a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The code above creates a heatmap that represents the confusion matrix above.\n",
    "#In this figure, different colors represent different numbers and similar colors represent similar numbers. \n",
    "#Heatmaps are a nice and convenient way to represent a matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d12023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a024fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can get a more comprehensive report on the classification with classification_report():\n",
    "# We use the code below to print the classification report\n",
    "\n",
    "print(classification_report(y, model.predict(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da7578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function also takes the actual and predicted outputs as arguments. \n",
    "#It returns a report on the classification as a dictionary if you provide output_dict=True or a string otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f0fea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d90ee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step Improve the Model\n",
    "#You can improve your model by setting different parameters. \n",
    "#For example, let‚Äôs work with the regularization strength C equal to 10.0, instead of the default value of 1.0:\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0)\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9953be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now you have another model with different parameters. \n",
    "#It‚Äôs also going to have a different probability matrix and a different set of coefficients and predictions:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e572ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c2f0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724a0150",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12cb6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As you can see, the absolute values of the intercept ùëè‚ÇÄ and the coefficient ùëè‚ÇÅ are larger. \n",
    "#This is the case because the larger value of C means weaker regularization, \n",
    "#or weaker penalization related to high values of ùëè‚ÇÄ and ùëè‚ÇÅ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50ab3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Different values of ùëè‚ÇÄ and ùëè‚ÇÅ imply a change of the logit ùëì(ùë•), different values of the probabilities ùëù(ùë•), \n",
    "#a different shape of the regression line, and possibly changes in other predicted outputs \n",
    "#and classification performance. The boundary value of ùë• for which ùëù(ùë•)=0.5 and ùëì(ùë•)=0 is higher now. It‚Äôs above 3. \n",
    "#In this case, you obtain all true predictions, as shown by the accuracy, confusion matrix, and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2541ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a30c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can get the actual predictions, based on the probability matrix and the values of ùëù(ùë•), with .predict():\n",
    "\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f035fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826be42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When you have nine out of ten observations classified correctly, \n",
    "#the accuracy of your model can be obtained with .score():\n",
    "\n",
    "model.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf6d709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ce0678",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y, model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619148a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d86acf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, model.predict(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabb469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The score (or accuracy) of 1 and the zeros in the lower-left and upper-right fields of the \n",
    "#confusion matrix indicate that the actual and predicted outputs are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cba7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8a9d7a6",
   "metadata": {},
   "source": [
    "# Example 2: Logistic Regression in Python with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b53bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Let‚Äôs solve another classification problem. \n",
    "#It‚Äôs similar to the previous one, except that the output differs in the second value. \n",
    "#The code is similar to the previous case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbd2aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c415466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import packages, functions, and classes\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75acfa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0af3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Get data\n",
    "x = np.arange(10).reshape(-1, 1)\n",
    "y = np.array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206204dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510b7bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create a model and train it\n",
    "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0)\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b47f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f5a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4-1: Evaluate the model\n",
    "p_pred = model.predict_proba(x) #obtain probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7e3fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b89c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4-2: Obtain predictions/classification results for values in x\n",
    "y_pred = model.predict(x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecabcd71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9292b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4-3: .score() takes the input (x) and output (y) as arguments \n",
    "#and returns the ratio of the number of correct predictions to the number of observations\n",
    "\n",
    "score_ = model.score(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dd0316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f874ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4-4: Obtain confusion matrix\n",
    "\n",
    "conf_m = confusion_matrix(y, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac65c58b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ef52f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4-5: Obtain classification report\n",
    "\n",
    "report = classification_report(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa4c498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aa1e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display x\n",
    "\n",
    "print('x:', x, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60df1885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdaa462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display y\n",
    "\n",
    "print('y:', y, sep='\\n', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55d49f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7e5129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display intercept\n",
    "\n",
    "print('intercept:', model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4493c566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1c63eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display coefficients\n",
    "\n",
    "print('coef:', model.coef_, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c6ce52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4de8c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display predited probabilities\n",
    "\n",
    "print('p_pred:', p_pred, sep='\\n', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a843aabc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439379ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display predicted values of y\n",
    "\n",
    "print('y_pred:', y_pred, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96639b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e235cbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display accuracy score\n",
    "\n",
    "print('score_:', score_, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcd2b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee574cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display confusion matrix\n",
    "\n",
    "print('conf_m:', conf_m, sep='\\n', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfef3699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba19558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display classification report\n",
    "\n",
    "print('report:', report, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12adde65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3125eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this case, the score (or accuracy) is 0.8. \n",
    "#There are two observations classified incorrectly. \n",
    "#One of them is a false negative, while the other is a false positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c8a1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35522828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc4c0b57",
   "metadata": {},
   "source": [
    "# Example 3: Logistic Regression in Python With StatsModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518543b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be690d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#You can also implement logistic regression in Python with the StatsModels package. \n",
    "#Typically, you want this when you need more statistical details related to models and results. \n",
    "#The procedure is similar to that of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f27a7da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a3dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Import Packages\n",
    "#All you need to import is NumPy and statsmodels.api:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b74fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85a870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Get Data\n",
    "#You can get the inputs and output the same way as you did with scikit-learn. \n",
    "#However, StatsModels doesn‚Äôt take the intercept ùëè‚ÇÄ into account, \n",
    "#and you need to include the additional column of ones in x. You do that with add_constant():\n",
    "\n",
    "\n",
    "x = np.arange(10).reshape(-1, 1)\n",
    "y = np.array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "x = sm.add_constant(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235882ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703dda91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_constant() takes the array x as the argument and returns a new array with the additional column of ones. \n",
    "#This is how x and y look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e643d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e672ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91f3f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is your data. The first column of x corresponds to the intercept ùëè‚ÇÄ. \n",
    "#The second column contains the original values of x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9890baed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daf42f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Create a Model and Train It\n",
    "#Your logistic regression model is going to be an instance of the class statsmodels.discrete.discrete_model.Logit. \n",
    "#This is how you can create one:\n",
    "\n",
    "model = sm.Logit(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a1ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that the first argument here is y, followed by x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d03b540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, you‚Äôve created your model and you should fit it with the existing data. \n",
    "#You do that with .fit() or, if you want to apply L1 regularization, with .fit_regularized():\n",
    "\n",
    "result = model.fit(method='newton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfcc3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb0a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The model is now ready, and the variable result holds useful data. \n",
    "#For example, you can obtain the values of ùëè‚ÇÄ and ùëè‚ÇÅ with .params:\n",
    "\n",
    "result.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a095fa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first element of the obtained array is the intercept ùëè‚ÇÄ, while the second is the slope ùëè‚ÇÅ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b35aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Evaluate the Model\n",
    "#You can use results to obtain the probabilities of the predicted outputs being equal to one:\n",
    "\n",
    "\n",
    "result.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de5aa00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135acd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict actual outputs. Remember that from the sigmoid function, when the probability for \n",
    "# an observation is >= 0.5, the output is predicted as \"success\" or 1\n",
    "\n",
    "#These probabilities are calculated with .predict(). \n",
    "#You can use their values to get the actual predicted outputs:\n",
    "\n",
    "(result.predict(x) >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f296c7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As an alternative to the cell above,You can also predict the outputs and assign to an object before displaying the object:\n",
    "\n",
    "predicted_outputs= (result.predict(x) >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc87a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display predicted outputs\n",
    "\n",
    "predicted_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d05d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notice that the predictions use 0.5 as a threshold for deciding whether the predicted value is 1 or not\n",
    "#for probabilities greater than or equal to 0.5,the prediction is a 1\n",
    "#for probabilities less than 0.5, the prediction is a 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc7693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The obtained array contains the predicted output values. \n",
    "#As you can see, ùëè‚ÇÄ, ùëè‚ÇÅ, and the probabilities obtained with scikit-learn and StatsModels are different. \n",
    "#This is the consequence of applying different iterative and approximate procedures and parameters. \n",
    "#However, in this case, you obtain the same predicted outputs as when you used scikit-learn.\n",
    "\n",
    "#You can obtain the confusion matrix with .pred_table():\n",
    "\n",
    "result.pred_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c542aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This example is the same as when you used scikit-learn because the predicted ouptuts are equal. \n",
    "#The confusion matrices you obtained with StatsModels and scikit-learn differ \n",
    "#in the types of their elements (floating-point numbers and integers)\n",
    "\n",
    "\n",
    "#.summary() and .summary2() get output data that you might find useful in some circumstances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a7cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option 1: Using .summary() to produce summary regression results\n",
    "\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e1d91e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de72caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option 2: Using .summary2() to produce summary regression results\n",
    "\n",
    "result.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c37d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are detailed reports with values that you can obtain with appropriate methods and attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1e29ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "205ac82e",
   "metadata": {},
   "source": [
    "# Example 3: Logistic Regression in Python: Handwriting Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea79b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#The previous examples illustrated the implementation of logistic regression in Python, \n",
    "#as well as some details related to this method. \n",
    "#The next example will show you how to use logistic regression to solve a real-world classification problem. \n",
    "#The approach is very similar to what you‚Äôve already seen, but with a larger dataset and several additional concerns.\n",
    "\n",
    "#This example is about image recognition. \n",
    "#To be more precise, you‚Äôll work on the recognition of handwritten digits. \n",
    "#You‚Äôll use a dataset with 1797 observations, each of which is an image of one handwritten digit. \n",
    "#Each image has 64 px, with a width of 8 px and a height of 8 px."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78307bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc47eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs\n",
    "#The inputs (ùê±) are vectors with 64 dimensions or values. \n",
    "#Each input vector describes one image. Each of the 64 values represents one pixel of the image. \n",
    "#The input values are the integers between 0 and 16, depending on the shade of gray for the corresponding pixel. \n",
    "\n",
    "#Output/target\n",
    "#The output (ùë¶) for each observation is an integer between 0 and 9, consistent with the digit on the image. \n",
    "#There are ten classes in total, each corresponding to one image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b18a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b58a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Import Packages\n",
    "#You‚Äôll need to import Matplotlib, NumPy, and several functions and classes from scikit-learn:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5aa01f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405a4e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2-1: Get Data\n",
    "#You can grab the dataset directly from scikit-learn with load_digits(). \n",
    "#It returns a tuple of the inputs and output:\n",
    "\n",
    "x, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d2f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now you have the data. This is how x and y look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b464ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c91463",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb65a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#That‚Äôs your data to work with. x is a multi-dimensional array with 1797 rows and 64 columns. \n",
    "#It contains integers from 0 to 16. y is an one-dimensional array with 1797 integers between 0 and 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e244e761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbed951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2-2: Split Data\n",
    "\n",
    "#It‚Äôs a good and widely-adopted practice to split the dataset you‚Äôre working with into two subsets. \n",
    "#These are the training set and the test set. This split is usually performed randomly. \n",
    "\n",
    "#You should use the training set to fit your model. \n",
    "#Once the model is fitted, you evaluate its performance with the test set. \n",
    "\n",
    "#It‚Äôs important not to use the test set in the process of fitting the model. \n",
    "\n",
    "#This approach enables an unbiased evaluation of the model.\n",
    "\n",
    "#One way to split your dataset into training and test sets is to apply train_test_split():\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b479614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split() accepts x and y. \n",
    "#It also takes test_size, which determines the size of the test set, \n",
    "#and random_state to define the state of the pseudo-random number generator, \n",
    "#as well as other optional arguments. This function returns a list with four arrays:\n",
    "\n",
    "x_train: the part of x used to fit the model\n",
    "x_test: the part of x used to evaluate the model\n",
    "y_train: the part of y that corresponds to x_train\n",
    "y_test: the part of y that corresponds to x_test\n",
    "\n",
    "#Once your data is split, you can forget about x_test and y_test until you define your model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217f0673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b347458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2-3: Scale Data\n",
    "\n",
    "#Standardization is the process of transforming data in a way such that the \n",
    "#mean of each column becomes equal to zero, and the standard deviation of each column is one. \n",
    "#This way, you obtain the same scale for all columns. Take the following steps to standardize your data:\n",
    "\n",
    "#a. Calculate the mean and standard deviation for each column.\n",
    "#b. Subtract the corresponding mean from each element.\n",
    "#c. Divide the obtained difference by the corresponding standard deviation.\n",
    "\n",
    "#It‚Äôs a good practice to standardize the input data that you use for logistic regression, \n",
    "#although in many cases it‚Äôs not necessary. Standardization might improve the performance of your algorithm. \n",
    "#It helps if you need to compare and interpret the weights. \n",
    "#It‚Äôs important when you apply penalization because the algorithm is \n",
    "# actually penalizing against the large values of the weights.\n",
    "\n",
    "#You can standardize your inputs by creating an instance of StandardScaler and calling .fit_transform() on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dd4b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can standardize your inputs by creating an instance of StandardScaler and calling .fit_transform() on it:\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8a8545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.fit_transform() fits the instance of StandardScaler to the array passed as the argument,\n",
    "# transforms this array, and returns the new, standardized array. \n",
    "#Now, x_train is a standardized input array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb63ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a93109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Create a Model and Train It\n",
    "#This step is very similar to the previous examples. \n",
    "#The only difference is that you use x_train and y_train subsets to fit the model. \n",
    "#Again, you should create an instance of LogisticRegression and call .fit() on it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbab56eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', C=0.05, multi_class='ovr', random_state=0)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad62cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When you‚Äôre working with problems with more than two classes, \n",
    "#you should specify the multi_class parameter of LogisticRegression. \n",
    "#It determines how to solve the problem:\n",
    "\n",
    "#'ovr' says to make the binary fit for each class.\n",
    "#'multinomial' says to apply the multinomial loss fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96be068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The last statement yields the following output since .fit() returns the model itself:\n",
    "\n",
    "\n",
    "#LogisticRegression(C=0.05, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='ovr', n_jobs=None, penalty='l2', random_state=0,\n",
    "                   solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66db1246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the parameters of your model. It‚Äôs now defined and ready for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43542735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627a94b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Evaluate the Model\n",
    "\n",
    "#You should evaluate your model similar to what you did in the previous examples, \n",
    "#with the difference that you‚Äôll mostly use x_test and y_test, \n",
    "#which are the subsets of your dataset not applied for training. \n",
    "\n",
    "#If you‚Äôve decided to standardize x_train, then the obtained model relies on the scaled data, \n",
    "#so x_test should be scaled as well with the same instance of StandardScaler:\n",
    "\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f53d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#That‚Äôs how you obtain a new, properly-scaled x_test. \n",
    "#In this case, you use .transform(), which only transforms the argument, without fitting the scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87693b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeeb7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can obtain the predicted outputs with .predict():\n",
    "\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3518b701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e789ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The variable y_pred is now bound to an array of the predicted outputs. \n",
    "#Note that you use x_test as the argument here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c066c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6600dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can obtain the accuracy with .score():\n",
    "\n",
    "model.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2647e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can obtain the accuracy with .score():\n",
    "\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aac63ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actually, you can get two values of the accuracy, one obtained with the training set and other with the test set. \n",
    "#It might be a good idea to compare the two, \n",
    "# as a situation where the training set accuracy is much higher might indicate overfitting. \n",
    "#The test set accuracy is more relevant for evaluating the performance on unseen data since it‚Äôs not biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe8d093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd37750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can get the confusion matrix with confusion_matrix():\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72476ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea226ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The obtained confusion matrix is large. In this case, it has 100 numbers. \n",
    "#This is a situation when it might be really useful to visualize it:\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "font_size = 4\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.set_xlabel('Predicted outputs', fontsize=font_size, color='black')\n",
    "ax.set_ylabel('Actual outputs', fontsize=font_size, color='black')\n",
    "ax.xaxis.set(ticks=range(10))\n",
    "ax.yaxis.set(ticks=range(10))\n",
    "ax.set_ylim(9.5, -0.5)\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618248f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The code above produces the figure above of the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be5a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The heatmap above illustrates the confusion matrix with numbers and colors. \n",
    "#You can see that the shades of purple represent small numbers (like 0, 1, or 2), \n",
    "#while green and yellow show much larger numbers (27 and above).\n",
    "\n",
    "#The numbers on the main diagonal (27, 32, ‚Ä¶, 36) show the number of correct predictions from the test set. \n",
    "#For example, there are 27 images with zero, 32 images of one, \n",
    "#and so on that are correctly classified. Other numbers correspond to the incorrect predictions. \n",
    "#For example, the number 1 in the third row and the first column shows that \n",
    "#there is one image with the number 2 incorrectly classified as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e74e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1145e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5: Finally, you can get the report on classification as a string or dictionary with classification_report():\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b788a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9c65bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The report above shows additional information, like the support and precision of classifying each digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b071928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df209f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beyond Logistic Regression in Python\n",
    "#Logistic regression is a fundamental classification technique. \n",
    "#It‚Äôs a relatively uncomplicated linear classifier. \n",
    "#Despite its simplicity and popularity, there are cases (especially with highly complex models) \n",
    "#where logistic regression doesn‚Äôt work well. In such circumstances, you can use other classification techniques:\n",
    "\n",
    "k-Nearest Neighbors\n",
    "Naive Bayes classifiers\n",
    "Support Vector Machines\n",
    "Decision Trees\n",
    "Random Forests\n",
    "Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35221884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17991e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310fef30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b88b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc50454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5387ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af36954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
