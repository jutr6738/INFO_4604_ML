{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dd3d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8057cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2717f5a4",
   "metadata": {},
   "source": [
    "# Example 1: Leave-One-Out Cross-Validation in Python (With Examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fbcef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To evaluate the performance of a model on a dataset, we need to measure how well the predictions made by the model \n",
    "#match the observed data.\n",
    "\n",
    "#One commonly used method for doing this is known as leave-one-out cross-validation (LOOCV), which uses the following approach:\n",
    "\n",
    "#1. Split a dataset into a training set and a testing set, using all but one observation as part of the training set.\n",
    "\n",
    "#2. Build a model using only data from the training set.\n",
    "\n",
    "#3. Use the model to predict the response value of the one observation left out of the model and calculate the mean squared error (MSE).\n",
    "\n",
    "#4. Repeat this process n times. Calculate the test MSE to be the average of all of the test MSE’s.\n",
    "\n",
    "#This notebook provides a step-by-step example of how to perform LOOCV for a given model in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f677d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "386baafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Load Necessary Libraries\n",
    "#First, we’ll load the necessary functions and libraries for this example:\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut          #Load LeaveOneOut from sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "from numpy import sqrt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bed0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec7f8a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Create the Data\n",
    "#Next, we create a pandas DataFrame that contains two predictor variables, x1 and x2, and a single response variable y.\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'y': [6, 8, 12, 14, 14, 15, 17, 22, 24, 23],\n",
    "                   'x1': [2, 5, 4, 3, 4, 6, 7, 5, 8, 9],\n",
    "                   'x2': [14, 12, 12, 13, 7, 8, 7, 4, 6, 5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216b29a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7dbc125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1461548083469744"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 3: Perform Leave-One-Out Cross-Validation\n",
    "#Next, we fit a multiple linear regression model to the dataset and perform LOOCV to evaluate the model performance.\n",
    "\n",
    "\n",
    "\n",
    "#define predictor and response variables\n",
    "X = df[['x1', 'x2']]\n",
    "y = df['y']\n",
    "\n",
    "#define cross-validation method to use\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "#build multiple linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "#use LOOCV to evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error',\n",
    "                         cv=cv, n_jobs=-1)\n",
    "\n",
    "#view mean absolute error (MAE)\n",
    "mean(absolute(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91f0780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f936c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the output we can see that the mean absolute error (MAE) was 3.146. \n",
    "#That is, the average absolute error between the model prediction and the actual observed data is 3.146.\n",
    "\n",
    "#In general, the lower the MAE, the more closely a model is able to predict the actual observations.\n",
    "\n",
    "#Another commonly used metric to evaluate model performance is the root mean squared error (RMSE). \n",
    "#The following code shows how to calculate this metric using LOOCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe23848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24c18975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6194564763855688"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define predictor and response variables\n",
    "X = df[['x1', 'x2']]\n",
    "y = df['y']\n",
    "\n",
    "#define cross-validation method to use\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "#build multiple linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "#use LOOCV to evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error',\n",
    "                         cv=cv, n_jobs=-1)\n",
    "\n",
    "#view RMSE\n",
    "sqrt(mean(absolute(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a06ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c9a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the output we can see that the root mean squared error (RMSE) was 3.619. \n",
    "#The lower the RMSE, the more closely a model is able to predict the actual observations.\n",
    "\n",
    "#In practice we typically fit several different models and compare \n",
    "#the RMSE or MAE of each model to decide which model produces the lowest test error rates \n",
    "#and is therefore the best model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c304e516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fbe2aab",
   "metadata": {},
   "source": [
    "# Example 2: Using cross_val_score in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6b8bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#cross_val_score is a common function to use during the testing and \n",
    "#validation phase of your machine learning model development. \n",
    "\n",
    "#cross_val_score is used to drive K-Fold Cross Validation in sklearn\n",
    "\n",
    "#Here we explain what it is, what you can use it for, and how to implement it in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79695aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross_val_score in sklearn, what is it?\n",
    "#Cross_val_score is a function in the scikit-learn package which trains \n",
    "#and tests a model over multiple folds of your dataset. \n",
    "\n",
    "#This cross validation method gives you a better understanding of model performance over the \n",
    "#whole dataset instead of just a single train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07adbc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The process that cross_val_score uses is typical for cross validation and follows these steps:\n",
    "\n",
    "#1. The number of folds is defined, by default this is 5\n",
    "#2. The dataset is split up according to these folds, where each fold has a unique set of testing data\n",
    "#3. A model is trained and tested for each fold\n",
    "#4. Each fold returns a metric for it's test data\n",
    "#5. The mean and standard deviation of these metrics can then be calculated to provide a single metric for the process\n",
    "\n",
    "\n",
    "#An illustration of how this works is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa70ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e570c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is cross_val_score used for?\n",
    "#Cross_val_score is used as a simple cross validation technique to prevent over-fitting and promote model generalisation.\n",
    "\n",
    "#The typical process of model development is to train a model on one fold of data and then test on another. \n",
    "#But how do we know that this single test dataset is representative? \n",
    "#This is why we use cross_val_score and cross validation more generally, \n",
    "#to train and test our model on multiple folds such that we can be sure \n",
    "#our model generalises well across the whole dataset and not just a single portion.\n",
    "\n",
    "#If we see that the metrics for all folds in cross_val_score are uniform \n",
    "#then it can be concluded that the model is able to generalise, \n",
    "#however if there are significant differences between them then \n",
    "#this may indicate over-fitting to certain folds and would need to be investigated further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf866be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4767951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many folds should I use in cross_val_score?\n",
    "#By default cross_val_score uses a 5-fold strategy, however this can be adjusted in the cv (hyper)parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a73bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#But how many folds should you choose?\n",
    "\n",
    "#There is unfortunately no hard and fast rules when it comes to how many folds you should choose. \n",
    "\n",
    "#A general rule of thumb though is that the number of folds should be as large as possible such \n",
    "#that each split has enough observations to generalise from and be tested on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fe9c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can I train my model using cross_val_score?\n",
    "\n",
    "#A common question developers have is whether cross_val_score can also function as a way of training the final model. \n",
    "#Unfortunately this is not the case. Cross_val_score is a way of assessing a model and it’s parameters, \n",
    "#and cannot be used for final training. Final training should take place on all available data and tested \n",
    "#using a set of data that has been held back from the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705a2656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can I use cross_val_score for classification and regression?\n",
    "\n",
    "#cross_val_score is a function which can be used for both classification and regression models. \n",
    "#The only major difference between the two is that by default cross_val_score uses Stratified KFold for classification, \n",
    "#and normal KFold for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8e4863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which metrics can I use in cross_val_score\n",
    "#By default cross_val_score uses the chosen model’s default scoring metric, \n",
    "#but this can be overridden with your metric of choice in the scoring parameter.\n",
    "\n",
    "#The common metrics provided by sklearn are passable as a string into this parameter, where some typical choices would be:\n",
    "\n",
    "‘accuracy’\n",
    "‘balanced_accuracy’\n",
    "‘roc_auc’\n",
    "‘f1’\n",
    "‘neg_mean_absolute_error’\n",
    "‘neg_root_mean_squared_error’\n",
    "‘r2’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47097d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to implement cross_val_score in Python?\n",
    "\n",
    "#This function is simple to implement in Python, but first let’s look at \n",
    "#how it fits into a typical machine learning development workflow:\n",
    "\n",
    "#1. Create a dataset\n",
    "#2. Run hyper-parameter tuning\n",
    "#3. Create model object with desired parameters\n",
    "#4. Run cross_val_score to test model performance\n",
    "#5. Train final model on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b17130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Therefore, in order to use cross_val_score we need to first have an \n",
    "#idea of the model we want to use and a prepared dataset to test it on.\n",
    "\n",
    "#Let’s look at how this process would look in Python using \n",
    "#a Linear Regression model and the Diabetes dataset from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "811a2dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score of -54.69 with a standard deviation of 1.37\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#load toy dataset (Diabetes dataset) from sklearn\n",
    "X, y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "#build linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "#use 5-Fold CV i.e. cv=5 to obtain performance scores\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "print(\"Mean score of %0.2f with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f6fbf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e1d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function parameters for cross_val_score\n",
    "#There are a number of parameters that you should be aware of when using cross_val_score. They are:\n",
    "\n",
    "#estimator - The model object to use to fit the data\n",
    "#X - The data to fit the model on\n",
    "#y - The target of the model\n",
    "#scoring - The error metric to use\n",
    "#cv - The number of splits to use i.e. k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d56f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary of the cross_val_score function\n",
    "#Cross_val_score is a method which runs cross validation on a \n",
    "#dataset to test whether the model can generalise over the whole dataset. \n",
    "\n",
    "#The function returns a list of one score per split, and the average of these scores \n",
    "#can be calculated to provide a single metric value for the dataset. \n",
    "#This is a function and a technique which you should add to your workflow to make sure you are developing highly performant models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669acc22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd51b452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b53e63f7",
   "metadata": {},
   "source": [
    "# Example 3: Using cross_validate in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d2af54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0218ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_validate #load cross_validate from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#load toy dataset\n",
    "X, y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "#define/select performance metric for your model\n",
    "metrics = ['neg_mean_absolute_error', 'r2']\n",
    "\n",
    "#build linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "#use 5-Fold CV i.e. cv=5 to obtain performance scores\n",
    "scores = cross_validate(model, X, y, cv=5, scoring=metrics)\n",
    "\n",
    "\n",
    "#Separate performance metrics\n",
    "mae_scores = scores['test_neg_mean_absolute_error']\n",
    "r2_scores = scores['test_r2']\n",
    "\n",
    "#Display mean and standard deviation of performance metrics\n",
    "print(\"Mean mae of %0.2f with a standard deviation of %0.2f\" % (mae_scores.mean(), mae_scores.std()))\n",
    "print(\"Mean r2 of %0.2f with a standard deviation of %0.2f\" % (r2_scores.mean(), r2_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291825dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f48afc49",
   "metadata": {},
   "source": [
    "# cross_validate vs. cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0001ed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_validate allows you to use more than one performance metric at a time \n",
    "#while cross_val_score allows you to use one performance metric at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "701ce7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean mae of -44.28 with a standard deviation of 2.10\n",
      "Mean r2 of 0.48 with a standard deviation of 0.05\n",
      "Mean score of -54.69 with a standard deviation of 1.37\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X, y = datasets.load_diabetes(return_X_y=True)\n",
    "model = LinearRegression()\n",
    "\n",
    "# Running cross_validate with multi metric\n",
    "metrics = ['neg_mean_absolute_error', 'r2']\n",
    "scores = cross_validate(model, X, y, cv=5, scoring=metrics)\n",
    "\n",
    "mae_scores = scores['test_neg_mean_absolute_error']\n",
    "r2_scores = scores['test_r2']\n",
    "\n",
    "print(\"Mean mae of %0.2f with a standard deviation of %0.2f\" % (mae_scores.mean(), mae_scores.std()))\n",
    "print(\"Mean r2 of %0.2f with a standard deviation of %0.2f\" % (r2_scores.mean(), r2_scores.std()))\n",
    "\n",
    "# Running cross_val_score with single metric\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "print(\"Mean score of %0.2f with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe1c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c276527d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29714d54",
   "metadata": {},
   "source": [
    "# Example 4: Using Grid Search + K-Fold Cross Validation to Build a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a03a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ed1d0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7828571428571429\n",
      "Best Hyperparameters: {'C': 1, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abiy3759\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "1440 fits failed out of a total of 2880.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abiy3759\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\abiy3759\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\abiy3759\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abiy3759\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\abiy3759\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\abiy3759\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abiy3759\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\abiy3759\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\abiy3759\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abiy3759\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\abiy3759\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\abiy3759\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abiy3759\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\abiy3759\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\abiy3759\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abiy3759\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\abiy3759\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\abiy3759\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\abiy3759\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.73373016 0.73230159        nan        nan        nan 0.53380952\n",
      " 0.53380952 0.53380952 0.53380952        nan        nan        nan\n",
      " 0.73373016 0.73230159        nan        nan        nan 0.53380952\n",
      " 0.53380952 0.53380952 0.53380952        nan        nan        nan\n",
      " 0.73373016 0.73230159        nan        nan        nan 0.53380952\n",
      " 0.53380952 0.53380952 0.53380952        nan        nan        nan\n",
      " 0.73373016 0.73230159        nan        nan        nan 0.53380952\n",
      " 0.58039683 0.58039683 0.57246032        nan        nan        nan\n",
      " 0.73373016 0.73230159        nan        nan        nan 0.53380952\n",
      " 0.69674603 0.69674603 0.69087302        nan        nan        nan\n",
      " 0.73373016 0.73230159        nan        nan        nan 0.77857143\n",
      " 0.78285714 0.78285714 0.75444444        nan        nan        nan\n",
      " 0.73373016 0.73230159        nan        nan        nan 0.75166667\n",
      " 0.7768254  0.7768254  0.77531746        nan        nan        nan\n",
      " 0.73373016 0.73230159        nan        nan        nan 0.75166667\n",
      " 0.75492063 0.75809524 0.75325397        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# grid search logistic regression model on the sonar dataset\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/sonar.csv'\n",
    "dataframe = read_csv(url, header=None)\n",
    "\n",
    "\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "\n",
    "\n",
    "# Establish instance of logistic Regression classifier\n",
    "model = LogisticRegression()\n",
    "\n",
    "# define model evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# define hyperparameter search space\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet'] #Regularization options/parameters\n",
    "space['C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "\n",
    "\n",
    "#The main hyperparameters we may tune in logistic regression are: solver, penalty, and \n",
    "#regularization strength, C (sklearn documentation). \n",
    "#Solver is the algorithm to use in the optimization problem. \n",
    "#The choices are {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'}, default='lbfgs'.\n",
    "\n",
    "#The trade-off parameter of logistic regression that determines the strength of the regularization is called C, \n",
    "#and higher values of C correspond to less regularization (where we can specify the regularization function).\n",
    "#C is actually the Inverse of regularization strength(lambda)\n",
    "\n",
    "\n",
    "# define search (via GridSearch)\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
    "\n",
    "# execute search - and use best hyperparameters to fit logistic regression model on data\n",
    "result = search.fit(X, y)\n",
    "\n",
    "# summarize and display result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "\n",
    "#Display best hyperparameters\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232a6214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27316d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3ccebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a790aa77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619792f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b08a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e026a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8bf701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5e132a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426f1877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b0c801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa68898d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd33f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
