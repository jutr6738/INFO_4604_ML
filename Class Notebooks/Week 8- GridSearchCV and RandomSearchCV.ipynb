{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64635dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccefcfae",
   "metadata": {},
   "source": [
    "# How to use GridSearchCV?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cec83df",
   "metadata": {},
   "source": [
    "# Support Vector Machines + GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053d3ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, let us see what are the various arguments that are taken by GridSearchCV function:\n",
    "\n",
    "\n",
    "sklearn.model_selection.GridSearchCV(estimator, param_grid,scoring=None,\n",
    "          n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, \n",
    "          pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False) \n",
    "\n",
    "\n",
    "\n",
    "1.estimator: Pass the model instance for which you want to check the hyperparameters.\n",
    "2.param_grid: the dictionary object that holds the hyperparameters you want to try\n",
    "3.scoring: evaluation metric that you want to use, you can simply pass a valid string/ object of evaluation metric\n",
    "4.cv: number of cross-validation you have to try for each selected set of hyperparameters\n",
    "5.verbose: you can set it to 1 to get the detailed result print out while you fit the data to GridSearchCV\n",
    "6.n_jobs: number of processes you wish to run in parallel for this task. If set to -1 it will use all available processors. \n",
    "\n",
    "#n_jobs: Specify the number of cores to use for key machine learning tasks.-1 means all cores\n",
    "#It you want to use multiprocessing to parallely train your model on all CPUs , then njobs will be helpful for you.\n",
    "#It just tells how many parallel processes you want to configure for training . \n",
    "#njobs = -1 means you want to use all the available cores , \n",
    "#and if you specify with a particular value e.g. 4, then those only cores will be used for training\n",
    "\n",
    "\n",
    "#You should be aware, and will probably notice if you enable verbose > 0, that printing to the screen is generally a very slow process. \n",
    "#The algorithm may run an order of magnitude slower, or more, with verbose enabled\n",
    "#You can also set verbose = True instead of a number >0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b67301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, let us see how to use GridSearchCV to improve the accuracy of our model. \n",
    "\n",
    "#Here we are going to train the model twice, once without using GridsearchCV(using the default hyperparameters) and \n",
    "#the other time we will use GridSearchCV to find the optimal values of hyperparameters for the dataset at hand. \n",
    "#We use the famous Breast Cancer Wisconsin (Diagnostic) Data Set which we import from the Scikit-learn library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec9d1c9",
   "metadata": {},
   "source": [
    "# Support Vector Machines Model without GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd0450d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90        66\n",
      "           1       0.91      0.97      0.94       105\n",
      "\n",
      "    accuracy                           0.92       171\n",
      "   macro avg       0.93      0.91      0.92       171\n",
      "weighted avg       0.93      0.92      0.92       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import all necessary libraries\n",
    "import sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split \n",
    " \n",
    "#load the dataset and split it into training and testing sets\n",
    "dataset = load_breast_cancer()\n",
    "X=dataset.data\n",
    "Y=dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "                        X,Y,test_size = 0.30, random_state = 101) \n",
    "\n",
    "# train the model on train set without using GridSearchCV \n",
    "model = SVC() \n",
    "\n",
    "#fit model on training data\n",
    "model.fit(X_train, y_train) \n",
    "   \n",
    "#obtain prediction results \n",
    "predictions = model.predict(X_test) \n",
    "\n",
    "#obtain and print performance metrics\n",
    "print(classification_report(y_test, predictions)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c2a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This classification report gives you a lot of information.\n",
    "\n",
    "#You get the precision, recall, F1 score, and accuracy. \n",
    "#You can see that your precision for both classes is relatively close, \n",
    "#and you also see an small difference in terms of recall for the two classes. \n",
    "#The difference between F1 scores is also not sizable.This means the model performed well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb0317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4975fd97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2495f8bb",
   "metadata": {},
   "source": [
    "# Support Vector Machines Model with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe3dd9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "{'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        63\n",
      "           1       0.98      0.97      0.98       108\n",
      "\n",
      "    accuracy                           0.97       171\n",
      "   macro avg       0.97      0.97      0.97       171\n",
      "weighted avg       0.97      0.97      0.97       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define parameter range \n",
    "param_grid = {'C': [0.1, 1, 10, 100],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'gamma':['scale', 'auto'],\n",
    "              'kernel': ['linear']}  \n",
    "   \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = True,n_jobs=-1) \n",
    "   \n",
    "# fitting the model with Grid Search \n",
    "grid.fit(X_train, y_train) \n",
    " \n",
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "grid_predictions = grid.predict(X_test) \n",
    "   \n",
    "# print classification report \n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b113dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note the following about the hyperparameters in param_grid:\n",
    "\n",
    "\n",
    "\n",
    "#C (or Cost hyperparameter)\n",
    "\n",
    "#C (aka Cost hyperparameter) is the penalty parameter of the error term. \n",
    "#It controls the trade off between smooth decision boundary and classifying the training points correctly. \n",
    "#Increasing C values may lead to overfitting the training data.\n",
    "\n",
    "#The C hyperparameter adds a penalty for each misclassified data point. \n",
    "#If C is small, the penalty for misclassified points is low so a decision boundary \n",
    "# with a large margin is chosen at the expense of a greater number of misclassifications\n",
    "\n",
    "#A high value of C means a higher penalty and is focused on achieving better accuracy by avoiding errors or misclassification \n",
    "#and hence opts for a SVM hyperplane with a better classification accuracy resulting in \n",
    "#a smaller margin hyperplane also known as Hard Margin\n",
    "\n",
    "\n",
    "\n",
    "#C: (Default = 1.0) Controls the tradeoff between smooth decision boundary and classifying training points correctly. \n",
    "#A large value of C will allow to include more training points therefore leading to a more intricate boundary.\n",
    "\n",
    "#The C parameter trades off correct classification of training examples against maximization of the decision function's margin\n",
    "\n",
    "\n",
    "#gamma\n",
    "\n",
    "#The gamma parameters can be seen as the inverse of the radius of influence of samples selected \n",
    "#by the model as support vectors. \n",
    "\n",
    "#gamma is a hyperparameter used with non-linear SVM. \n",
    "#One of the most commonly used non-linear kernels is the radial basis function (RBF). \n",
    "#Gamma parameter of RBF controls the distance of the influence of a single training point\n",
    "\n",
    "#gamma: Defines how far the influence of a single training example reaches. \n",
    "#A High gamma value means only the closest points to the decision boundary will carry the weigth leading to a smoother boundary\n",
    "#gamma is a parameter for non linear hyperplanes. \n",
    "#The higher the gamma value it tries to exactly fit the training data set gammas\n",
    "\n",
    "#The default value for gamma is 3. \n",
    "#gamma is the kernel coefficient for 'rbf', 'poly', and 'sigmoid'. \n",
    "#If gamma is 'auto', then 1/n features will be used instead\n",
    "\n",
    "#Kernel\n",
    "\n",
    "#SVM algorithms use a group of mathematical functions that are known as kernels. \n",
    "#The function of a kernel is to require data as input and transform it into the desired form. \n",
    "\n",
    "#Different SVM algorithms use differing kinds of kernel functions. \n",
    "#These kernel functions are of different kinds. For example: linear, nonlinear, polynomial, radial basis function (RBF), and sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae092b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This classification report gives you a lot of information.\n",
    "\n",
    "#You get the precision, recall, F1 score, and accuracy. \n",
    "#You can see that your precision for both classes is relatively close, \n",
    "#and you also see an small difference in terms of recall for the two classes. \n",
    "#The difference between F1 scores is also not sizable.This means the model performed better than the model without GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcea808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It might seem that {‘C’: 100, ‘gamma’: ‘scale’, ‘kernel’: ‘linear’} are the best values for hyperparameters for an SVM model. \n",
    "#This is not the case, the above-mentioned hyperparameters may be the best for the dataset we are working on. \n",
    "#But for any other dataset, the SVM model can have different optimal values for hyperparameters that may improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a88f77a",
   "metadata": {},
   "source": [
    "# Random Forest Model without Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc06f337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.datasets import load_breast_cancer \n",
    "from sklearn.metrics import (precision_score,\n",
    "                            accuracy_score)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "df = load_breast_cancer()\n",
    "X=df.data\n",
    "y=df.target\n",
    "\n",
    "#You instantiate a model, call .fit() to train it, and then call .predict() to get predictions. \n",
    "#We instantiate a RandomForestClassifier() and keep all default parameter values.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "#Fit model without Grid Search\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Make predictions for the test set\n",
    "y_pred_test = rfc.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a28bd286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9707602339181286"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View accuracy score\n",
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bc7d363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59,   4],\n",
       "       [  1, 107]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View confusion matrix for test data and predictions\n",
    "confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5369c524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96        63\n",
      "           1       0.96      0.99      0.98       108\n",
      "\n",
      "    accuracy                           0.97       171\n",
      "   macro avg       0.97      0.96      0.97       171\n",
      "weighted avg       0.97      0.97      0.97       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# View the classification report for test data and predictions\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0518f62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce011e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca4704c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04466b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13ffb3ee",
   "metadata": {},
   "source": [
    "# Random Forest Model with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23ddc3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'max_features': 5}\n",
      "0.9597435897435898\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "df = load_breast_cancer()\n",
    "X=df.data\n",
    "y=df.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "forest_params = [{'max_depth': list(range(10, 15)), 'max_features': list(range(0,14))}]\n",
    "\n",
    "#Fit model with Grid Search\n",
    "clf = GridSearchCV(rfc, forest_params, cv = 10, scoring='accuracy')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#best_params_ will give the combination of hyperparameters along with values that give the best performance of our estimate specified\n",
    "print(clf.best_params_)\n",
    "\n",
    "#best_score_ is the average of all cv folds for a single combination of the parameters you specify in the tuned_params\n",
    "print(clf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae96f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note for Random Forest\n",
    "\n",
    "#max depth: \n",
    "#max_depth is the number of splits that each decision tree is allowed to make. \n",
    "#If the number of splits is too low, the model underfits the data and if it is too high the model overfits. \n",
    "#Generally, we go with a max depth of 3, 5, or 7\n",
    "\n",
    "#max features\n",
    "\n",
    "#Random forest takes random subsets of features and tries to find the best split. \n",
    "#max_features helps to find the number of features to take into account in order to make the best split. \n",
    "#max_feature is the number of features to consider each time to make the split decision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21caacd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "489eb36b",
   "metadata": {},
   "source": [
    "# Logistic Regression + Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f730a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab339c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below we will use hyperparameter optimization to discover a well-performing model configuration for the sonar dataset.\n",
    "\n",
    "#The sonar dataset is a standard machine learning dataset comprising 208 rows of data with 60 numerical input variables and a target variable with two class values, e.g. binary classification.\n",
    "\n",
    "#Using a test harness of repeated stratified 10-fold cross-validation with three repeats, a naive model can achieve an accuracy of about 53 percent. \n",
    "#A top-performing model can achieve accuracy on this same test harness of about 88 percent. \n",
    "#This provides the bounds of expected performance on this dataset.\n",
    "\n",
    "#The dataset involves predicting whether sonar returns indicate a rock or simulated mine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "393cc000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7897619047619049\n",
      "Best Hyperparameters: {'C': 4.878363034905756, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "# Random Search logistic regression model on the sonar dataset\n",
    "#Author - Jason Brownlee\n",
    "\n",
    "from scipy.stats import loguniform\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/sonar.csv'\n",
    "dataframe = read_csv(url, header=None)\n",
    "\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "\n",
    "# define model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# define evaluation/validation strategy\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# define search space\n",
    "\n",
    "#The search space is a dictionary where names are arguments to the model and values are distributions from which to draw samples. \n",
    "#We will optimize the solver, the penalty, and the C hyperparameters of the model with discrete distributions \n",
    "#for the solver and penalty type and a log-uniform distribution from 1e-5 to 100 for the C value.\n",
    "\n",
    "#Log-uniform is useful for searching penalty values as we often explore values at different orders of magnitude, \n",
    "#at least as a first step.\n",
    "\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "space['C'] = loguniform(1e-5, 100)\n",
    "\n",
    "#C is known as a \"Cost hyperparameter.\" \n",
    "\n",
    "#Parameters are numbers that tell the model what to do with the characteristics, \n",
    "#whereas hyperparameters instruct the model on how to choose parameters.\n",
    "#Regularization will penalize the extreme parameters, the extreme values in the training data leads to overfitting.\n",
    "\n",
    "#Hyperparameters are very critical in building robust and accurate models. \n",
    "#Hyperparameters help us find the balance between bias and variance\n",
    "\n",
    "#A high value of C tells the algorithm to give more weight to the training data. \n",
    "#A lower value of C will indicate the model to give complexity more weight at the cost of fitting the data. \n",
    "#Thus, a high Hyperparameter value for C indicates that training data is more important and reflects the real world data, \n",
    "#whereas low value is just the opposite of this\n",
    "\n",
    "\n",
    "\n",
    "#Next, we can define the search procedure with all of these elements.\n",
    "\n",
    "#Importantly, we must set the number of iterations or samples to draw from the search space via the “n_iter” argument. \n",
    "#In this case, we will set it to 500.\n",
    "\n",
    "# define search\n",
    "search = RandomizedSearchCV(model, space, n_iter=500, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "\n",
    "# execute search\n",
    "result = search.fit(X, y)\n",
    "\n",
    "# summarize (and display) results\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d0b124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#At the end of the search, you can access all of the results via attributes on the class. \n",
    "#Perhaps the most important attributes are the best score observed and the hyperparameters that achieved the best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c81bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once you know the set of hyperparameters that achieve the best result, you can then define a new model, \n",
    "# set the values of each hyperparameter, then fit the model on all available data. \n",
    "#This model can then be used to make predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e603d49b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283754f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9dbae4e",
   "metadata": {},
   "source": [
    "# Logistic Regression + Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a307a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the Grid Search is much like using the Random Search for classification.\n",
    "\n",
    "#The main difference is that the search space must be a discrete grid to be searched. \n",
    "#This means that instead of using a log-uniform distribution for C, we can specify discrete values on a log scale.\n",
    "\n",
    "#Additionally, the GridSearchCV class does not take a number of iterations, \n",
    "#as we are only evaluating combinations of hyperparameters in the grid.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87839350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search logistic regression model on the sonar dataset\n",
    "#Author - Jason Brownlee\n",
    "\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/sonar.csv'\n",
    "dataframe = read_csv(url, header=None)\n",
    "\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "\n",
    "# define model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "space['C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
    "\n",
    "# execute search\n",
    "result = search.fit(X, y)\n",
    "\n",
    "# summarize (and display) results\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac714603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the example above may take a moment. \n",
    "#It is fast because we are using a small search space and a fast model to fit and evaluate. \n",
    "#Again, you may see some warnings during the optimization for invalid configuration combinations. These can be safely ignored.\n",
    "\n",
    "#At the end of the run, the best score and hyperparameter configuration that achieved the best performance are reported.\n",
    "\n",
    "#Your specific results will vary given the stochastic nature of the optimization procedure. \n",
    "#Try running the example a few times.\n",
    "\n",
    "#In this case, we can see that the best configuration achieved an accuracy of about 78.2% \n",
    "#which is also fair and the specific values for the solver, penalty and C hyperparameters used to achieve that score. \n",
    "#Interestingly, the results are very similar to those found via the random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f875a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcb096f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1011863c",
   "metadata": {},
   "source": [
    "# Regression + Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14f00fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter Optimization for Regression\n",
    "\n",
    "#The code below will use hyperparameter optimization to discover a top-performing \n",
    "#model configuration for the auto insurance dataset.\n",
    "\n",
    "#The auto insurance dataset is a standard machine learning dataset \n",
    "# comprising 63 rows of data with 1 numerical input variable and a numerical target variable.\n",
    "\n",
    "#Using a test harness of repeated stratified 10-fold cross-validation with 3 repeats, \n",
    "#a naive model can achieve a mean absolute error (MAE) of about 66.\n",
    "#A top performing model can achieve a MAE on this same test harness of about 28. \n",
    "#This provides the bounds of expected performance on this dataset.\n",
    "\n",
    "#The dataset involves predicting the total amount in claims (thousands of Swedish Kronor) \n",
    "#given the number of claims for different geographical regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2b6048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d385c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -29.12510803005527\n",
      "Best Hyperparameters: {'alpha': 0.00011012287475478404, 'fit_intercept': True, 'normalize': True, 'solver': 'sag'}\n"
     ]
    }
   ],
   "source": [
    "#Random Search linear regression model on the auto insurance dataset\n",
    "#Author - Jason Brownlee\n",
    "\n",
    "#The main difference in regression compared to classification is the choice of the scoring method.\n",
    "\n",
    "#For regression, performance is often measured using an error, which is minimized, \n",
    "#with zero representing a model with perfect skill. \n",
    "\n",
    "#The hyperparameter optimization procedures in scikit-learn assume a maximizing score. \n",
    "#Therefore a version of each error metric is provided that is made negative.\n",
    "#This means that large positive errors become large negative errors, \n",
    "#good performance are small negative values close to zero and perfect skill is zero.\n",
    "\n",
    "#The sign of the negative MAE can be ignored when interpreting the result.\n",
    "\n",
    "#In this case we will mean absolute error (MAE) and \n",
    "#a maximizing version of this error is available by setting the “scoring” argument to “neg_mean_absolute_error“.\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import loguniform\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#Running the example downloads the dataset and splits it into input and output elements. \n",
    "#As expected, we can see that there are 63 rows of data with 1 input variable.\n",
    "\n",
    "# load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/auto-insurance.csv'\n",
    "dataframe = read_csv(url, header=None)\n",
    "\n",
    "# split into input and output elements\n",
    "\n",
    "\n",
    "data = dataframe.values\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "\n",
    "#Next, we can use hyperparameter optimization to find a good model configuration for the auto insurance dataset.\n",
    "\n",
    "#To keep things simple, we will focus on a linear model, the linear regression model \n",
    "#and the common hyperparameters tuned for this model.\n",
    "\n",
    "\n",
    "# define model\n",
    "model = Ridge()\n",
    "\n",
    "# define evaluation\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "\n",
    "#Random Search for Regression\n",
    "#Configuring and using the random search hyperparameter optimization procedure for regression \n",
    "#is much like using it for classification.\n",
    "\n",
    "#In this case, we will configure the important hyperparameters of the linear regression implementation, \n",
    "#including the solver, alpha, fit_intercept, and normalize.\n",
    "\n",
    "#We will use a discrete distribution of values in the search space for all except the “alpha” \n",
    "#argument which is a penalty term, in which case we will use a log-uniform distribution \n",
    "#as we did in the case for logistic regression for the “C” argument of logistic regression.\n",
    "\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['svd', 'cholesky', 'lsqr', 'sag']\n",
    "space['alpha'] = loguniform(1e-5, 100)\n",
    "space['fit_intercept'] = [True, False]\n",
    "space['normalize'] = [True, False]\n",
    "\n",
    "# define search\n",
    "search = RandomizedSearchCV(model, space, n_iter=500, scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv, random_state=1)\n",
    "\n",
    "# execute search\n",
    "result = search.fit(X, y)\n",
    "\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc608c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the example may take a moment. \n",
    "#It is fast because we are using a small search space and a fast model to fit and evaluate. \n",
    "#You may see some warnings during the optimization for invalid configuration combinations. These can be safely ignored.\n",
    "\n",
    "#At the end of the run, the best score and hyperparameter configuration that achieved the best performance are reported.\n",
    "\n",
    "#Your specific results will vary given the stochastic nature of the optimization procedure. \n",
    "#Try running the example a few times.\n",
    "\n",
    "#In this case, we can see that the best configuration achieved a MAE of about 29.1, \n",
    "#which is very close to the best performance on the model. \n",
    "#We can then see the specific hyperparameter values that achieved this result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b196d2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac8ebb6b",
   "metadata": {},
   "source": [
    "# Regression + GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf610ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As a grid search, we cannot define a distribution to sample and \n",
    "# instead must define a discrete grid of hyperparameter values. \n",
    "#As such, we will specify the “alpha” argument as a range of values on a log-10 scale.\n",
    "\n",
    "#Grid search for regression requires that the “scoring” be specified, much as we did for random search.\n",
    "\n",
    "#In this case, we will again use the negative MAE scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52d500b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -29.23817478943268\n",
      "Best Hyperparameters: {'alpha': 1, 'fit_intercept': True, 'normalize': False, 'solver': 'sag'}\n"
     ]
    }
   ],
   "source": [
    "#Grid Search linear regression model on the auto insurance dataset\n",
    "#Author - Jason Brownlee\n",
    "\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/auto-insurance.csv'\n",
    "dataframe = read_csv(url, header=None)\n",
    "\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "\n",
    "# define model\n",
    "model = Ridge()\n",
    "\n",
    "# define evaluation\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['svd', 'cholesky', 'lsqr', 'sag']\n",
    "space['alpha'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "space['fit_intercept'] = [True, False]\n",
    "space['normalize'] = [True, False]\n",
    "\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv)\n",
    "\n",
    "# execute search\n",
    "result = search.fit(X, y)\n",
    "\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39584845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the example may take a minute. \n",
    "#It is fast because we are using a small search space and a fast model to fit and evaluate. \n",
    "#Again, you may see some warnings during the optimization for invalid configuration combinations. \n",
    "#These can be safely ignored.\n",
    "\n",
    "#At the end of the run, the best score and hyperparameter configuration that achieved the best performance are reported.\n",
    "\n",
    "#Your specific results will vary given the stochastic nature of the optimization procedure. \n",
    "#Try running the example a few times.\n",
    "\n",
    "#In this case, we can see that the best configuration achieved a MAE of about 29.2, \n",
    "#which is nearly identical to what we achieved with the random search in the previous section. \n",
    "#Interestingly, the hyperparameters are also nearly identical, which is good confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeaf914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a1de0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af86b5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d9dfb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dad81ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc23cb6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8066a5d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5368a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7c1108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1789e641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7348e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
