{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce62a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a0ae426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.5-py3-none-win_amd64.whl (70.9 MB)\n",
      "     --------------------------------------- 70.9/70.9 MB 16.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\abiy3759\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\abiy3759\\anaconda3\\lib\\site-packages (from xgboost) (1.9.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.5\n"
     ]
    }
   ],
   "source": [
    "#Install xgboost\n",
    "\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ed05ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699d431f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a245c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# Load the dataset\n",
    "diabetes = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956d87e0",
   "metadata": {},
   "source": [
    "# Example 1: Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77baf363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3769.8656234983728\n"
     ]
    }
   ],
   "source": [
    "# importing utility modules\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import datasets\n",
    "\n",
    "# importing machine learning models for prediction\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load the dataset\n",
    "df = datasets.load_diabetes()\n",
    "\n",
    "# getting target data from the dataframe\n",
    "\n",
    "X = df[\"data\"]\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Splitting between train data into training and validation dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "# initializing all the model objects with default parameters\n",
    "model_1 = LinearRegression()\n",
    "model_2 = xgb.XGBRegressor()\n",
    "model_3 = RandomForestRegressor()\n",
    "\n",
    "# training all the model on the training dataset\n",
    "model_1.fit(X_train, y_train)\n",
    "model_2.fit(X_train, y_train)\n",
    "model_3.fit(X_train, y_train)\n",
    "\n",
    "# predicting the output on the validation dataset\n",
    "pred_1 = model_1.predict(X_test)\n",
    "pred_2 = model_2.predict(X_test)\n",
    "pred_3 = model_3.predict(X_test)\n",
    "\n",
    "# final prediction after averaging on the prediction of all 3 models\n",
    "pred_final = (pred_1+pred_2+pred_3)/3.0\n",
    "\n",
    "# printing the mean squared error between real value and predicted value\n",
    "print(mean_squared_error(y_test, pred_final))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cd9741",
   "metadata": {},
   "source": [
    "# Example 2: Max Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1253888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abiy3759\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5148796558495095\n"
     ]
    }
   ],
   "source": [
    "# importing utility modules\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import datasets\n",
    "\n",
    "# importing machine learning models for prediction\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# importing voting classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Load the dataset\n",
    "df = datasets.load_breast_cancer()\n",
    "\n",
    "# getting target data from the dataframe\n",
    "\n",
    "X = df[\"data\"]\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Splitting between train data into training and validation dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "# initializing all the model objects with default parameters\n",
    "model_1 = LogisticRegression()\n",
    "model_2 = XGBClassifier()\n",
    "model_3 = RandomForestClassifier()\n",
    "\n",
    "# Making the final model using voting classifier\n",
    "final_model = VotingClassifier(estimators=[('lr', model_1), ('xgb', model_2), ('rf', model_3)], voting='hard')\n",
    "\n",
    "# training all the model on the train dataset\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# predicting the output on the test dataset\n",
    "pred_final = final_model.predict(X_test)\n",
    "\n",
    "# printing log loss between actual and predicted value\n",
    "print(log_loss(y_test, pred_final))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b33b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bca524c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8cd436b",
   "metadata": {},
   "source": [
    "# Example 3: Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5276a2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3774.9589267474994\n"
     ]
    }
   ],
   "source": [
    "# importing utility modules\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import datasets\n",
    "\n",
    "# importing machine learning models for prediction\n",
    "import xgboost as xgb\n",
    "\n",
    "# importing bagging module\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "# Load the dataset\n",
    "df = datasets.load_diabetes()\n",
    "\n",
    "# getting target data from the dataframe\n",
    "\n",
    "X = df[\"data\"]\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Splitting between train data into training and validation dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "# initializing the bagging model using XGboost as base model with default parameters\n",
    "model = BaggingRegressor(base_estimator=xgb.XGBRegressor())\n",
    "\n",
    "# training model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predicting the output on the test dataset\n",
    "pred_final = model.predict(X_test)\n",
    "\n",
    "# printing the mean squared error between real value and predicted value\n",
    "print(mean_squared_error(y_test, pred_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb792db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bed7c41",
   "metadata": {},
   "source": [
    "# Example 4: Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfb1ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8b61953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3344.435278647636\n"
     ]
    }
   ],
   "source": [
    "# importing utility modules\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import datasets\n",
    "\n",
    "# importing machine learning models for prediction\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Load the dataset\n",
    "df = datasets.load_diabetes()\n",
    "\n",
    "# getting target data from the dataframe\n",
    "\n",
    "X = df[\"data\"]\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Splitting between train data into training and validation dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "# initializing the boosting module with default parameters\n",
    "model = GradientBoostingRegressor()\n",
    "\n",
    "# training the model on the train dataset\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predicting the output on the test dataset\n",
    "pred_final = model.predict(X_test)\n",
    "\n",
    "# printing the mean squared error between real value and predicted value\n",
    "print(mean_squared_error(y_test, pred_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e05399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6a9862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: The scikit-learn provides several modules/methods for ensemble methods. \n",
    "#Please note the accuracy of a method does not suggest one method is superior to another. \n",
    "#The article aims to give a brief introduction to ensemble methodsâ€“not to compare between them. \n",
    "#The programmer must use a method that suits the data\n",
    "\n",
    "#Also ignore the high RMSE and look at the structure/setup of of the ensemble methods for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4776842b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de5d9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a7927a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9138c252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65132372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc54488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f769be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759f016c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a52af43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e866265c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a4949c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737031be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0e051f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf7b92c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1a06f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a75140c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14430ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef7fcca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006410c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13864fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95455d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1102919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b0453d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ba843d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7654033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a383c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5682c20b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ebf6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50fedd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a653f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869a49f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc3e728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a79bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing utility modules\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# importing machine learning models for prediction\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# loading train data set in dataframe from train_data.csv file\n",
    "df = pd.read_csv(\"train_data.csv\")\n",
    "\n",
    "# getting target data from the dataframe\n",
    "target = df[\"target\"]\n",
    "\n",
    "# getting train data from the dataframe\n",
    "train = df.drop(\"target\")\n",
    "\n",
    "# Splitting between train data into training and validation dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.20)\n",
    "\n",
    "# initializing all the model objects with default parameters\n",
    "model_1 = LinearRegression()\n",
    "model_2 = xgb.XGBRegressor()\n",
    "model_3 = RandomForestRegressor()\n",
    "\n",
    "# training all the model on the training dataset\n",
    "model_1.fit(X_train, y_target)\n",
    "model_2.fit(X_train, y_target)\n",
    "model_3.fit(X_train, y_target)\n",
    "\n",
    "# predicting the output on the validation dataset\n",
    "pred_1 = model_1.predict(X_test)\n",
    "pred_2 = model_2.predict(X_test)\n",
    "pred_3 = model_3.predict(X_test)\n",
    "\n",
    "# final prediction after averaging on the prediction of all 3 models\n",
    "pred_final = (pred_1+pred_2+pred_3)/3.0\n",
    "\n",
    "# printing the mean squared error between real value and predicted value\n",
    "print(mean_squared_error(y_test, pred_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644a5185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e7a039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492fd47f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddb4a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b597e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5740cae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067cb80d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81e787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9a1067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f3505f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdd1000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
